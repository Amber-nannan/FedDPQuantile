{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from util_fdp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvg_case2 = load_pickle('case_federated_hete_cvg.pkl')\n",
    "mae_case2 = load_pickle('case_federated_hete_mae.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5000: {0.3: {0.25: {1: np.float64(0.994), 5: np.float64(0.98), 'log': np.float64(1.0)}, 0.9: {1: np.float64(0.988), 5: np.float64(1.0), 'log': np.float64(1.0)}}, 0.5: {0.25: {1: np.float64(0.992), 5: np.float64(1.0), 'log': np.float64(1.0)}, 0.9: {1: np.float64(0.924), 5: np.float64(0.996), 'log': np.float64(1.0)}}, 0.8: {0.25: {1: np.float64(0.997), 5: np.float64(1.0), 'log': np.float64(1.0)}, 0.9: {1: np.float64(0.952), 5: np.float64(0.993), 'log': np.float64(0.983)}}}, 50000: {0.3: {0.25: {1: np.float64(1.0), 5: np.float64(0.915), 'log': np.float64(0.999)}, 0.9: {1: np.float64(0.87), 5: np.float64(0.976), 'log': np.float64(0.954)}}, 0.5: {0.25: {1: np.float64(0.987), 5: np.float64(0.91), 'log': np.float64(0.488)}, 0.9: {1: np.float64(0.956), 5: np.float64(0.98), 'log': np.float64(0.991)}}, 0.8: {0.25: {1: np.float64(0.997), 5: np.float64(0.915), 'log': np.float64(1.0)}, 0.9: {1: np.float64(0.895), 5: np.float64(0.945), 'log': np.float64(0.181)}}}}\n",
      "{5000: {0.3: {0.25: {1: np.float64(0.011019182662447393), 5: np.float64(0.01157129762623894), 'log': np.float64(0.0044457084422743435)}, 0.9: {1: np.float64(0.006377531676907188), 5: np.float64(0.004040809572013032), 'log': np.float64(0.006217352684792251)}}, 0.5: {0.25: {1: np.float64(0.011856664555620384), 5: np.float64(0.009618385051904784), 'log': np.float64(0.004957613554786477)}, 0.9: {1: np.float64(0.008494699677365703), 5: np.float64(0.005483229620081417), 'log': np.float64(0.004561117479865939)}}, 0.8: {0.25: {1: np.float64(0.020683896253449675), 5: np.float64(0.02024995495246389), 'log': np.float64(0.013423304148067099)}, 0.9: {1: np.float64(0.007855742637781828), 5: np.float64(0.008881328012069688), 'log': np.float64(0.014801154520876093)}}}, 50000: {0.3: {0.25: {1: np.float64(0.003619846467311883), 5: np.float64(0.0036952364073878025), 'log': np.float64(0.0018059531463836772)}, 0.9: {1: np.float64(0.002277465696291589), 5: np.float64(0.0010289564162735134), 'log': np.float64(0.0014719885560916367)}}, 0.5: {0.25: {1: np.float64(0.006145710087731252), 5: np.float64(0.00839918196663269), 'log': np.float64(0.013700961566444085)}, 0.9: {1: np.float64(0.001936668214251751), 5: np.float64(0.000989889856051162), 'log': np.float64(0.0005766890852412397)}}, 0.8: {0.25: {1: np.float64(0.007192945258862295), 5: np.float64(0.006380622392428345), 'log': np.float64(0.001678094569750105)}, 0.9: {1: np.float64(0.0021527280767467856), 5: np.float64(0.003663233958458797), 'log': np.float64(0.012593544209726876)}}}}\n"
     ]
    }
   ],
   "source": [
    "print(cvg_case2)\n",
    "print(mae_case2)\n",
    "# {5000: {0.3: {0.9: {'log': {(0.51, 100): np.float64(1.0)}}}}}\n",
    "# {5000: {0.3: {0.9: {'log': {(0.51, 100): np.float64(0.0037842187136836085)}}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m E, cvg_map, mae_map \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m, cvg_log, mae_log), (\u001b[38;5;241m5\u001b[39m, cvg_5, mae_5)]:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# for E, cvg_map, mae_map in [(5, cvg_5, mae_5)]:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# for E, cvg_map, mae_map in [('log', cvg_log, mae_log)]:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (a, b), cvg \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcvg_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     13\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m\"\u001b[39m: E,\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(a),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(mae_map[(a, b)])\n\u001b[1;32m     19\u001b[0m         })\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cvg_log = cvg_case2[5000][0.8][0.25]['log']\n",
    "mae_log = mae_case2[5000][0.8][0.25]['log']\n",
    "cvg_5   = cvg_case2[5000][0.8][0.25][5]\n",
    "mae_5   = mae_case2[5000][0.8][0.25][5]\n",
    "\n",
    "rows = []\n",
    "for E, cvg_map, mae_map in [('log', cvg_log, mae_log), (5, cvg_5, mae_5)]:\n",
    "# for E, cvg_map, mae_map in [(5, cvg_5, mae_5)]:\n",
    "# for E, cvg_map, mae_map in [('log', cvg_log, mae_log)]:\n",
    "    for (a, b), cvg in cvg_map.items():\n",
    "        rows.append({\n",
    "            \"E\": E,\n",
    "            \"a\": float(a),\n",
    "            \"b\": float(b),\n",
    "            \"cvg\": float(cvg),\n",
    "            \"mae\": float(mae_map[(a, b)])\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values(by=[\"E\",\"a\",\"b\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# df.to_csv(\"combined_cvg_mae_T5000_tau0.3_rs0.9.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_table(data_ci, data_mae, caption=\"Results\",\n",
    "                            label=\"tab:combined\"):\n",
    "    # 自动获取所有n值并按数字顺序排序\n",
    "    all_n = sorted(set(list(data_ci.keys()) + list(data_mae.keys())), key=int)\n",
    "    latex_code = f\"\"\n",
    "    for n in all_n:\n",
    "        # 添加n标题行\n",
    "        latex_code += f\"\\\\multicolumn{{6}}{{c}}{{\\\\textbf{{T = {n}}}}} \\\\\\\\\\n\"\n",
    "        latex_code += \"\\\\midrule\\n\"\n",
    "        \n",
    "        # 遍历所有tau和r组合\n",
    "        for tau in sorted(data_ci[n].keys(), key=float):\n",
    "            for r_val in data_ci[n][tau].keys():\n",
    "                # 生成行内容\n",
    "                row = f\"{tau} & {r_val if isinstance(r_val, str) else r_val} \"\n",
    "                \n",
    "                # 遍历所有E值\n",
    "                for e in data_ci[n][tau][r_val].keys():\n",
    "                    ci = data_ci[n][tau][r_val].get(e, \"--\")\n",
    "                    mae = data_mae[n][tau][r_val].get(e, \"--\")\n",
    "                    cell = f\"& {ci:.3f}({mae:.4f}) \" if isinstance(ci, float) and isinstance(mae, float) else \"& -- \"\n",
    "                    row += cell\n",
    "                \n",
    "                latex_code += row + \"\\\\\\\\\\n\"\n",
    "            \n",
    "            # 添加tau之间的分隔线\n",
    "            latex_code += \"\\\\hline\\n\"\n",
    "    latex_code += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{table}\"\"\"\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = generate_combined_table(cvg_case2, mae_case2)\n",
    "with open(\"combined_table.tex\", \"w\") as f:\n",
    "    f.write(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train_func(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_func(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ray.tune import Checkpoint\n",
    "\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train_func(model, optimizer, train_loader)\n",
    "        acc = test_func(model, test_loader)\n",
    "\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint = None\n",
    "            if (i + 1) % 5 == 0:\n",
    "                # This saves the model to the trial directory\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                )\n",
    "                checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            # Send the current training result back to Tune\n",
    "            tune.report({\"mean_accuracy\": acc}, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-29 02:28:02</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:06.07        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.8/72.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/36 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_8f5a1_00000</td><td>TERMINATED</td><td>172.17.0.3:234083</td><td style=\"text-align: right;\">   0.65443</td><td style=\"text-align: right;\">0.078125</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.23464</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=234083)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_mnist_2025-04-29_02-27-52/train_mnist_8f5a1_00000_0_momentum=0.6544_2025-04-29_02-27-56/checkpoint_000000)\n",
      "\u001b[36m(train_mnist pid=234083)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/train_mnist_2025-04-29_02-27-52/train_mnist_8f5a1_00000_0_momentum=0.6544_2025-04-29_02-27-56/checkpoint_000001)\n",
      "2025-04-29 02:28:02,284\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_mnist_2025-04-29_02-27-52' in 0.0089s.\n",
      "2025-04-29 02:28:02,307\tINFO tune.py:1041 -- Total run time: 6.14 seconds (6.06 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10 ** (-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.1, 0.9),\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# `ray.init(address=\"auto\")`\n",
    "\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_mnist,\n",
    "    param_space=search_space,\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
